{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"mdnjFEB2gu5J"},"outputs":[],"source":["import numpy as np\n","import pyrender\n","import smplx\n","import torch\n","import trimesh\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n","\n","def normalize_angle(x):\n","    return torch.atan2(torch.sin(x), torch.cos(x))\n","\n","def quat_to_angle_axis(q):\n","    # type: (Tensor) -> Tuple[Tensor, Tensor]\n","    # computes axis-angle representation from quaternion q\n","    # q must be normalized\n","    min_theta = 1e-5\n","    qx, qy, qz, qw = 0, 1, 2, 3\n","\n","    sin_theta = torch.sqrt(1 - q[..., qw] * q[..., qw])\n","    angle = 2 * torch.acos(q[..., qw])\n","    angle = normalize_angle(angle)\n","    sin_theta_expand = sin_theta.unsqueeze(-1)\n","    axis = q[..., qx:qw] / sin_theta_expand\n","\n","    mask = sin_theta > min_theta\n","    default_axis = torch.zeros_like(axis)\n","    default_axis[..., -1] = 1\n","\n","    angle = torch.where(mask, angle, torch.zeros_like(angle))\n","    mask_expand = mask.unsqueeze(-1)\n","    axis = torch.where(mask_expand, axis, default_axis)\n","    return angle, axis\n","\n","def angle_axis_to_exp_map(angle, axis):\n","    # type: (Tensor, Tensor) -> Tensor\n","    # compute exponential map from axis-angle\n","    angle_expand = angle.unsqueeze(-1)\n","    exp_map = angle_expand * axis\n","    return exp_map\n","\n","def quat_to_exp_map(q):\n","    # type: (Tensor) -> Tensor\n","    # compute exponential map from quaternion\n","    # q must be normalized\n","    angle, axis = quat_to_angle_axis(q)\n","    exp_map = angle_axis_to_exp_map(angle, axis)\n","    return exp_map\n","\n","def obs_visualize(obs):\n","    '''\n","    obs numpy shape (1, 4+63) root_rot + dof_pos\n","\n","    #save obs for experiment\n","    obs_save = torch.cat((self._humanoid_root_states[:1, 3:7], self._dof_pos[:1]), dim=-1)\n","    obs_save = obs_save.detach().cpu().numpy()\n","    import datetime\n","    time_str = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n","    obs_folder = os.path.abspath(\"obs/new\")\n","    # Create output folder if needed\n","    os.makedirs(obs_folder, exist_ok=True)\n","    savepath = os.path.join(obs_folder, time_str+\".npy\")\n","    np.save(savepath, obs_save)\n","    \n","    '''\n","    DOF_BODY_IDS = [3, 6, 9, 13, 16, 18, 20, 12, 15, 14, 17, 19, 21, 2, 5, 8, 11, 1, 4, 7, 10]\n","    body_model = 'smpl'\n","    body_model_path = './body_model/smpl_model/models' #share drive\n","    '''\n","    obs = torch.from_numpy(obs).view(-1, 1, 63)\n","    \n","    rot = torch.zeros(list(obs.shape[:-2]) + [24, 3])\n","    rot[..., DOF_BODY_IDS, :] = obs[..., 4:].view(list(obs.shape[:-2]) + [21, 3])\n","    rot[..., 0, :] = quat_to_exp_map(obs[:, 0, :4])\n","    '''\n","    obs = torch.from_numpy(obs)\n","    pred24_4 = obs[..., 3:].view(-1, 4)\n","    rot = quat_to_exp_map(pred24_4).view(-1, 24, 3)\n","    \n","    body_model = smplx.create(model_path=body_model_path, model_type=body_model)\n","    faces = body_model.faces\n","\n","    vertices = body_model(global_orient=rot[..., :1, :], body_pose=rot[..., 1:, :]).vertices[0].detach().numpy()\n","    # vertices = body_model().vertices[0].detach().numpy()\n","\n","    original_mesh = trimesh.Trimesh(vertices=vertices, faces=faces)\n","    original_mesh.export('obsvistest.ply')\n","    mesh = pyrender.Mesh.from_trimesh(original_mesh)\n","    scene = pyrender.Scene(bg_color=[0, 0, 0, 0], ambient_light=(0.3, 0.3, 0.3))\n","    # scene = pyrender.Scene()\n","    scene.add(mesh, 'mesh')\n","\n","    # add camera pose\n","    camera_pose = np.array([[1, 0, 0, 0],\n","                            [0, 1, 0, 0],\n","                            [0, 0, 1, 3],\n","                            [0, 0, 0, 1]])\n","    # use this to make it to center\n","    camera = pyrender.camera.PerspectiveCamera(yfov=1)\n","    scene.add(camera, pose=camera_pose)\n","\n","    # Get the lights from the viewer\n","    light = pyrender.SpotLight(color=np.ones(3), intensity=3.0, innerConeAngle=np.pi/3.0, outerConeAngle=np.pi/3.0)\n","    scene.add(light, pose=camera_pose)\n","\n","    # offscreen render\n","    r = pyrender.OffscreenRenderer(viewport_width=512, viewport_height=512)\n","    color, depth = r.render(scene, flags=pyrender.RenderFlags.RGBA)\n","    # plt.figure(figsize=(8, 8))\n","    # plt.imshow(color[:, :, 0:3])\n","    # plt.show()\n","    cv2.imwrite('obsvistest.png', color[:, :, 0:3])\n","    return color[:, :, 0:3]\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"UZp4NSzJgu5Q","outputId":"5ea7fa1a-c7cf-457a-bd2d-5526271edf41"},"outputs":[{"ename":"ValueError","evalue":"Unknown model type models, exiting!","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn [3], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m obs_99dim \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((rotation_traj[\u001b[38;5;241m0\u001b[39m], root_traj[\u001b[38;5;241m0\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#print(traj.shape)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mobs_visualize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_99dim\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn [1], line 81\u001b[0m, in \u001b[0;36mobs_visualize\u001b[0;34m(obs)\u001b[0m\n\u001b[1;32m     78\u001b[0m pred24_4 \u001b[38;5;241m=\u001b[39m obs[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m3\u001b[39m:]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     79\u001b[0m rot \u001b[38;5;241m=\u001b[39m quat_to_exp_map(pred24_4)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m body_model \u001b[38;5;241m=\u001b[39m \u001b[43msmplx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m faces \u001b[38;5;241m=\u001b[39m body_model\u001b[38;5;241m.\u001b[39mfaces\n\u001b[1;32m     84\u001b[0m vertices \u001b[38;5;241m=\u001b[39m body_model(global_orient\u001b[38;5;241m=\u001b[39mrot[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m1\u001b[39m, :], body_pose\u001b[38;5;241m=\u001b[39mrot[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:, :])\u001b[38;5;241m.\u001b[39mvertices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n","File \u001b[0;32m~/anaconda3/envs/motion/lib/python3.8/site-packages/smplx/body_models.py:2410\u001b[0m, in \u001b[0;36mcreate\u001b[0;34m(model_path, model_type, **kwargs)\u001b[0m\n\u001b[1;32m   2408\u001b[0m     \u001b[39mreturn\u001b[39;00m FLAME(model_path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   2409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2410\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnknown model type \u001b[39m\u001b[39m{\u001b[39;00mmodel_type\u001b[39m}\u001b[39;00m\u001b[39m, exiting!\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: Unknown model type models, exiting!"]}],"source":["data_path = '/home/wenbin/kangning/motion/RIOT/decision-transformer/gym/motion_train_dataset/004882c9-da8d-4a76-90a8-039d9a690d73.npy'\n","obs = np.load(data_path, allow_pickle=True)\n","od_dict = obs.item()\n","rotation_traj = od_dict[\"rotation\"][\"arr\"]\n","root_traj = od_dict[\"root_translation\"][\"arr\"]\n","traj_len = len(rotation_traj)\n","rotation_traj = rotation_traj.reshape(traj_len, -1)\n","obs_99dim = np.concatenate((rotation_traj[0], root_traj[0]), axis=0)\n","#print(traj.shape)\n","img = obs_visualize(obs_99dim)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.8.15","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"26bc301650b35ad26f23f070b3fc5cb08238aa9b6aac36a77934c616402f94a6"}}},"nbformat":4,"nbformat_minor":0}
